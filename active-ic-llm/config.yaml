model_name: bert-base-uncased
al_method: random
num_shots: 8
pool_fraction: 0.2

classification_tasks: ["sst2", "boolq"]

multichoice_tasks: [
  "hellaswag",
  "allenai_ai2_arc_ARC-Challenge",  # arc-c
  "allenai_ai2_arc_ARC-Easy",       # arc-e
  "winogrande_winogrande_xl",       # winogrande
  "piqa",
  "social_i_qa",                    # siqa
  "openbookqa"                      # obqa
]

commonsense_tasks: [
  "hellaswag",
  "allenai_ai2_arc_ARC-Challenge",
  "allenai_ai2_arc_ARC-Easy",
  "winogrande_winogrande_xl",
  "piqa",
  "social_i_qa",
  "openbookqa"
]

math_reasoning_tasks: [
  "gsm8k_main",                     # gsm8k
  "aqua_rat",
  "allenai_lila",                   
  "ChilleD_MultiArith",            # multiarith
  "SingleEq",                       # singleeq
  "SVAMP"
]

instruction_following_tasks: [
  "databricks_databricks-dolly-15k",     # dolly_eval
  "HuggingFaceH4_ultrachat_200k",        # vicuna_eval
  "yizhongw_self_instruct",              # self_instruct
  "Dinosaur_dinosaur-sub-superni"        # s_ni
]

data_dir: data
standardized_dir: /home/aneek/src/ActiveLearning/data/standardized
raw_dir: /home/aneek/src/ActiveLearning/data/raw
outputs_dir: outputs

max_seq_length: 128
seed: 42
device: cuda
num_gpus: 4

perplexity_batch_size: 8

# Directory used to cache sentence embeddings for the similarity
# sampler. If embeddings for a dataset are present here, they will be
# loaded instead of recomputed.
embedding_cache_dir: embedding_cache

# Number of evaluation examples processed together when querying the
# model. Adjust this to balance speed and memory usage.
inference_batch_size: 8

